{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a71e02-81bb-4438-a55d-dc463aa073c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_array(arr):\n",
    "    \"\"\"Normalizes an array to have a range between 0 and 1\"\"\"\n",
    "    min_val = np.min(arr)\n",
    "    max_val = np.max(arr)\n",
    "    return (arr - min_val) / (max_val - min_val)\n",
    "\"\"\"\n",
    "Here we implement all the BM25 variations mentioned. \n",
    "\"\"\"\n",
    "\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, cpu_count\n",
    "#from textblob import TextBlob\n",
    "\n",
    "\n",
    "class BM25:\n",
    "    def __init__(self, corpus: List[str], tokenizer):\n",
    "        self.corpus_size = 0\n",
    "        self.avgdl = 0\n",
    "        self.doc_freqs = []\n",
    "        self.idf = {}\n",
    "        self.doc_len = []\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        if tokenizer:\n",
    "            corpus = self._tokenize_corpus(corpus)\n",
    "\n",
    "        nd = self._initialize(corpus)\n",
    "        self._calc_idf(nd)\n",
    "\n",
    "    def _initialize(self, corpus):\n",
    "        # word -> number of documents with word\n",
    "        nd = defaultdict(int)\n",
    "        num_doc = 0\n",
    "        for document in corpus:\n",
    "            self.doc_len.append(len(document))\n",
    "            num_doc += len(document)\n",
    "\n",
    "            frequencies = defaultdict(int)      # word: frequency\n",
    "            for word in document:\n",
    "                frequencies[word] += 1\n",
    "            self.doc_freqs.append(frequencies)\n",
    "\n",
    "            for word, _ in frequencies.items():\n",
    "                nd[word] += 1\n",
    "            self.corpus_size += 1\n",
    "\n",
    "        self.avgdl = num_doc / self.corpus_size\n",
    "        return nd\n",
    "\n",
    "    def _tokenize_corpus(self, corpus):\n",
    "        pool = Pool(cpu_count())\n",
    "        tokenized_corpus = pool.map(self.tokenizer, corpus)\n",
    "        return tokenized_corpus\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    \n",
    "    def get_scores(self, query):\n",
    "        raise NotImplementedError()\n",
    "    def get_bm25scores(self, query):\n",
    "        raise NotImplementedError()    \n",
    "\n",
    "    def get_batch_scores(self, query, doc_ids):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    #initialise eval metric for variate models\n",
    "    def eval_metric_func(self, query):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_top_n(self, query:str, documents, n=5):\n",
    "        assert self.corpus_size == len(\n",
    "            documents\n",
    "        ), \"The documents given don't match the index corpus!\"\n",
    "        if self.tokenizer:\n",
    "            query = self.tokenizer(query)\n",
    "        scores = self.get_bm25scores(query)\n",
    "        top_n = np.argsort(scores)[::-1][:n]\n",
    "        return [documents[i] for i in top_n], scores[top_n]\n",
    "    \n",
    "    def get_top_var_n(self, query:str, documents, n=5):\n",
    "        assert self.corpus_size == len(\n",
    "            documents\n",
    "        ), \"The documents given don't match the index corpus!\"\n",
    "        if self.tokenizer:\n",
    "            query = self.tokenizer(query)\n",
    "        scores = self.get_scores(query)\n",
    "        top_n = np.argsort(scores)[::-1][:n]\n",
    "        return [documents[i] for i in top_n], scores[top_n]\n",
    "    \n",
    "    def eval_metr(self, score, l_score, n=10):\n",
    "                    \n",
    "            #normalise scores\n",
    "        norm_score = normalize_array(score)\n",
    "        norm_l_score = normalize_array(l_score)\n",
    "        \"\"\"\n",
    "        #rev sort top_n l_score and store doc_id/index\n",
    "        rev_norm_l_score = sorted(norm_l_score, reverse = True)\n",
    "        top_n = n\n",
    "        idx_list = []\n",
    "        for i in range(top_n):\n",
    "            idx_list.append(norm_l_score.get(rev_norm_l_score[i]))\n",
    "        \"\"\"\n",
    "        #calc scores\n",
    "        #relevance scoring can be 0,1,2,3; so we take 0.98 and above as reasonable for tp/fp ~98%\n",
    "        ml_norm_score = [int(i>0.9995) for i in norm_score]\n",
    "        ml_norm_l_score = [int(i>0.9995) for i in norm_l_score]\n",
    "\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        for i in range(n):\n",
    "            if ml_norm_l_score[i]==1 and ml_norm_score[i]==1:\n",
    "                tp+=1\n",
    "            if ml_norm_l_score[i]==0 and ml_norm_score[i]==0:\n",
    "                tn+=1\n",
    "            if ml_norm_l_score[i]==1 and ml_norm_score[i]==0:\n",
    "                fp+=1\n",
    "            if ml_norm_l_score[i]==0 and ml_norm_score[i]==1:\n",
    "                fn+=1\n",
    "        #metric set 1\n",
    "        if tp+fp!=0:\n",
    "            precision = tp/(tp+fp)\n",
    "        else:\n",
    "            precision = 0\n",
    "        if tp+fn!=0:\n",
    "            \n",
    "            recall = tp/(tp+fn)\n",
    "        else:\n",
    "            recall = 0\n",
    "        #accuracy = tp/(tp+fp+tn+fn)\n",
    "        if  (2 * tp + fp + fn)!=0:\n",
    "            \n",
    "            f1 = 2 * tp / (2 * tp + fp + fn)\n",
    "        else:\n",
    "            f1 = 0\n",
    "        #metric set 2\n",
    "        \n",
    "        ndcg = 0\n",
    "        #ndcg\n",
    "        dcg = l_score[0]\n",
    "        for i in range(1, len(l_score)):\n",
    "            dcg += l_score[i] / (np.log2(i + 1))\n",
    "        idcg = score[0]\n",
    "        for i in range(1, len(score)):\n",
    "            idcg += score[i] / (np.log2(i + 1))\n",
    "\n",
    "        # normalized discounted cumulative gain (NDCG) calculation\n",
    "        if idcg == 0:\n",
    "            ndcg = 0\n",
    "        else:\n",
    "            ndcg =  dcg / idcg\n",
    "        \n",
    "        \n",
    "        return [precision, recall, f1, ndcg]\n",
    "        \n",
    "        \n",
    "class BM25Okapi(BM25):\n",
    "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, epsilon=0.25):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.epsilon = epsilon\n",
    "        super().__init__(corpus, tokenizer)\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        \"\"\"\n",
    "        Calculates frequencies of terms in documents and in corpus.\n",
    "        This algorithm sets a floor on the idf values to eps * average_idf\n",
    "        \"\"\"\n",
    "        # collect idf sum to calculate an average idf for epsilon value\n",
    "        idf_sum = 0\n",
    "        # collect words with negative idf to set them a special epsilon value.\n",
    "        # idf can be negative if word is contained in more than half of documents\n",
    "        negative_idfs = []\n",
    "        for word, freq in nd.items():\n",
    "            idf = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
    "            self.idf[word] = idf\n",
    "            idf_sum += idf\n",
    "            if idf < 0:\n",
    "                negative_idfs.append(word)\n",
    "        self.average_idf = idf_sum / len(self.idf)\n",
    "\n",
    "        eps = self.epsilon * self.average_idf\n",
    "        for word in negative_idfs:\n",
    "            self.idf[word] = eps\n",
    "\n",
    "    def get_bm25scores(self, query):\n",
    "        \"\"\"\n",
    "        The ATIRE BM25 variant uses an idf function which uses a log(idf) score. To prevent negative idf scores,\n",
    "        this algorithm also adds a floor to the idf value of epsilon.\n",
    "        See [Trotman, A., X. Jia, M. Crane, Towards an Efficient and Effective Search Engine] for more info\n",
    "        :param query:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (\n",
    "                q_freq\n",
    "                * (self.k1 + 1)\n",
    "                / (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "            )\n",
    "        return score\n",
    "    def get_scores(self, query):\n",
    "        \"\"\"\n",
    "        The ATIRE BM25 variant uses an idf function which uses a log(idf) score. To prevent negative idf scores,\n",
    "        this algorithm also adds a floor to the idf value of epsilon.\n",
    "        See [Trotman, A., X. Jia, M. Crane, Towards an Efficient and Effective Search Engine] for more info\n",
    "        :param query:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (\n",
    "                q_freq\n",
    "                * (self.k1 + 1)\n",
    "                / (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "            )\n",
    "        return score\n",
    "\n",
    "    def get_batch_scores(self, query, doc_ids):\n",
    "        \"\"\"\n",
    "        Calculate bm25 scores between query and subset of all docs\n",
    "        \"\"\"\n",
    "        assert all(di < len(self.doc_freqs) for di in doc_ids)\n",
    "        score = np.zeros(len(doc_ids))\n",
    "        doc_len = np.array(self.doc_len)[doc_ids]\n",
    "        for q in query:\n",
    "            q_freq = np.array([(self.doc_freqs[di].get(q) or 0) for di in doc_ids])\n",
    "            score += (self.idf.get(q) or 0) * (\n",
    "                q_freq\n",
    "                * (self.k1 + 1)\n",
    "                / (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "            )\n",
    "        return score.tolist()\n",
    "\"\"\"\n",
    "def get_sentiment(sentence):\n",
    "    blob = TextBlob(sentence)\n",
    "\n",
    "    # Sentiment from  -1 (negative) to 1 (positive)\n",
    "    # Subjectivity: from 0 (objective) to 1 (subjective)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "\n",
    "    return round(polarity, 2), round(subjectivity, 2)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#new model bm25L for testing+eval metric function\n",
    "\n",
    "class BM25L(BM25):\n",
    "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, delta=0.5):\n",
    "        # Algorithm specific parameters\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.delta = delta\n",
    "        super().__init__(corpus, tokenizer)\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        for word, freq in nd.items():\n",
    "            idf = math.log(self.corpus_size + 1) - math.log(freq + 0.5)\n",
    "            self.idf[word] = idf\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            ctd = q_freq / (1 - self.b + self.b * doc_len / self.avgdl)\n",
    "            score += (self.idf.get(q) or 0) * (self.k1 + 1) * (ctd + self.delta) / \\\n",
    "                     (self.k1 + ctd + self.delta)\n",
    "        return score\n",
    "\n",
    "    def get_batch_scores(self, query, doc_ids):\n",
    "        \"\"\"\n",
    "        Calculate bm25 scores between query and subset of all docs\n",
    "        \"\"\"\n",
    "        assert all(di < len(self.doc_freqs) for di in doc_ids)\n",
    "        score = np.zeros(len(doc_ids))\n",
    "        doc_len = np.array(self.doc_len)[doc_ids]\n",
    "        for q in query:\n",
    "            q_freq = np.array([(self.doc_freqs[di].get(q) or 0) for di in doc_ids])\n",
    "            ctd = q_freq / (1 - self.b + self.b * doc_len / self.avgdl)\n",
    "            score += (self.idf.get(q) or 0) * (self.k1 + 1) * (ctd + self.delta) / \\\n",
    "                     (self.k1 + ctd + self.delta)\n",
    "        return score.tolist()\n",
    "\n",
    "    def get_bm25scores(self, query):\n",
    "        \"\"\"\n",
    "        The ATIRE BM25 variant uses an idf function which uses a log(idf) score. To prevent negative idf scores,\n",
    "        this algorithm also adds a floor to the idf value of epsilon.\n",
    "        See [Trotman, A., X. Jia, M. Crane, Towards an Efficient and Effective Search Engine] for more info\n",
    "        :param query:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (\n",
    "                q_freq\n",
    "                * (self.k1 + 1)\n",
    "                / (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "            )\n",
    "        return score\n",
    " \n",
    "class BM25Plus(BM25):\n",
    "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, delta=1):\n",
    "        # Algorithm specific parameters\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.delta = delta\n",
    "        super().__init__(corpus, tokenizer)\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        for word, freq in nd.items():\n",
    "            idf = math.log((self.corpus_size + 1) / freq)\n",
    "            self.idf[word] = idf\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (self.delta + (q_freq * (self.k1 + 1)) /\n",
    "                                               (self.k1 * (1 - self.b + self.b * doc_len / self.avgdl) + q_freq))\n",
    "        return score\n",
    "\n",
    "    def get_batch_scores(self, query, doc_ids):\n",
    "        \"\"\"\n",
    "        Calculate bm25 scores between query and subset of all docs\n",
    "        \"\"\"\n",
    "        assert all(di < len(self.doc_freqs) for di in doc_ids)\n",
    "        score = np.zeros(len(doc_ids))\n",
    "        doc_len = np.array(self.doc_len)[doc_ids]\n",
    "        for q in query:\n",
    "            q_freq = np.array([(self.doc_freqs[di].get(q) or 0) for di in doc_ids])\n",
    "            score += (self.idf.get(q) or 0) * (self.delta + (q_freq * (self.k1 + 1)) /\n",
    "                                               (self.k1 * (1 - self.b + self.b * doc_len / self.avgdl) + q_freq))\n",
    "        return score.tolist()\n",
    "    def get_bm25scores(self, query):\n",
    "        \"\"\"\n",
    "        The ATIRE BM25 variant uses an idf function which uses a log(idf) score. To prevent negative idf scores,\n",
    "        this algorithm also adds a floor to the idf value of epsilon.\n",
    "        See [Trotman, A., X. Jia, M. Crane, Towards an Efficient and Effective Search Engine] for more info\n",
    "        :param query:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (\n",
    "                q_freq\n",
    "                * (self.k1 + 1)\n",
    "                / (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "            )\n",
    "        return score\n",
    "\n",
    "    #excluding bm25adpt, bm25t, bm11, bm15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd11d0-47d7-4d35-b251-343cb6fe4aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "305181a9-d4a5-4e7a-a3d6-152ba032e415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.3.23)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7675b88-cacd-4a5a-83ed-4cf9cc62ba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creates the Index and prepares index for the BM25 models\n",
    "\"\"\"\n",
    "import string\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import nltk\n",
    "#from src.model import BM25Okapi\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text, used before indexing and query search\n",
    "    \"\"\"\n",
    "    text = text.lower()  # convert to lowercase\n",
    "    # remove punctuation\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    # remove stop words\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "\n",
    "def load(idxpath):\n",
    "    \"\"\"Loads the pickle file.\n",
    "    \"\"\"\n",
    "    with open(idxpath, \"rb\") as idx_file:\n",
    "        pkl_data = pickle.load(idx_file)\n",
    "    return pkl_data['model'], pkl_data['data_index']\n",
    "\n",
    "\n",
    "def create(fpath, idxpath):\n",
    "    \"\"\" Creates index and returns the corpus dataframe\n",
    "    \"\"\"\n",
    "    dataset_file = fpath\n",
    "    col_names = [\"doc_id\", \"category\", \"subcategory\", \"title\",\n",
    "                 \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"]\n",
    "    df_original = pd.read_csv(dataset_file, sep=\"\\t\",\n",
    "                              header=None, names=col_names)\n",
    "    print(f\"Data dimensions: {df_original.shape}\")\n",
    "\n",
    "    # drop when df[\"title\"] & df[\"abstract\"] are nan\n",
    "    df_no_nan = df_original.dropna(subset=[\"title\", \"abstract\"])\n",
    "    print(f\"Data dimensions after removing nan: {df_no_nan.shape}\")\n",
    "\n",
    "    # preprocess the text\n",
    "    df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
    "    df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n",
    "    corpus = df_no_nan[\"preprocessed_text\"].tolist()\n",
    "\n",
    "    # Create and save index\n",
    "    model = BM25Okapi(corpus, tokenizer=nltk.word_tokenize)\n",
    "    pkl_data = {\n",
    "        \"model\": model,\n",
    "        \"data_index\": df_no_nan.index,\n",
    "    }\n",
    "    with open(idxpath, \"wb\") as idx_file:\n",
    "        pickle.dump(pkl_data, idx_file)\n",
    "    return df_original\n",
    "\n",
    "\n",
    "\n",
    "def create_var_l(fpath, idxpath):\n",
    "    \"\"\" Creates index and returns the corpus dataframe\n",
    "    \"\"\"\n",
    "    dataset_file = fpath\n",
    "    col_names = [\"doc_id\", \"category\", \"subcategory\", \"title\",\n",
    "                 \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"]\n",
    "    df_original = pd.read_csv(dataset_file, sep=\"\\t\",\n",
    "                              header=None, names=col_names)\n",
    "    print(f\"Data dimensions: {df_original.shape}\")\n",
    "\n",
    "    # drop when df[\"title\"] & df[\"abstract\"] are nan\n",
    "    df_no_nan = df_original.dropna(subset=[\"title\", \"abstract\"])\n",
    "    print(f\"Data dimensions after removing nan: {df_no_nan.shape}\")\n",
    "\n",
    "    # preprocess the text\n",
    "    df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
    "    df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n",
    "    corpus = df_no_nan[\"preprocessed_text\"].tolist()\n",
    "\n",
    "    # Create and save index\n",
    "    model = BM25L(corpus, tokenizer=nltk.word_tokenize)\n",
    "    pkl_data = {\n",
    "        \"model\": model,\n",
    "        \"data_index\": df_no_nan.index,\n",
    "    }\n",
    "    with open(idxpath, \"wb\") as idx_file:\n",
    "        pickle.dump(pkl_data, idx_file)\n",
    "    return df_original\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb82f5e-0535-4d11-9ad6-daeaa2eb08f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_var_plus(fpath, idxpath):\n",
    "    \"\"\" Creates index and returns the corpus dataframe\n",
    "    \"\"\"\n",
    "    dataset_file = fpath\n",
    "    col_names = [\"doc_id\", \"category\", \"subcategory\", \"title\",\n",
    "                 \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"]\n",
    "    df_original = pd.read_csv(dataset_file, sep=\"\\t\",\n",
    "                              header=None, names=col_names)\n",
    "    print(f\"Data dimensions: {df_original.shape}\")\n",
    "\n",
    "    # drop when df[\"title\"] & df[\"abstract\"] are nan\n",
    "    df_no_nan = df_original.dropna(subset=[\"title\", \"abstract\"])\n",
    "    print(f\"Data dimensions after removing nan: {df_no_nan.shape}\")\n",
    "\n",
    "    # preprocess the text\n",
    "    df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
    "    df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n",
    "    corpus = df_no_nan[\"preprocessed_text\"].tolist()\n",
    "\n",
    "    # Create and save index\n",
    "    model = BM25Plus(corpus, tokenizer=nltk.word_tokenize)\n",
    "    pkl_data = {\n",
    "        \"model\": model,\n",
    "        \"data_index\": df_no_nan.index,\n",
    "    }\n",
    "    with open(idxpath, \"wb\") as idx_file:\n",
    "        pickle.dump(pkl_data, idx_file)\n",
    "    return df_original\n",
    "\n",
    "\n",
    "def create_var_11(fpath, idxpath):\n",
    "    \"\"\" Creates index and returns the corpus dataframe\n",
    "    \"\"\"\n",
    "    dataset_file = fpath\n",
    "    col_names = [\"doc_id\", \"category\", \"subcategory\", \"title\",\n",
    "                 \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"]\n",
    "    df_original = pd.read_csv(dataset_file, sep=\"\\t\",\n",
    "                              header=None, names=col_names)\n",
    "    print(f\"Data dimensions: {df_original.shape}\")\n",
    "\n",
    "    # drop when df[\"title\"] & df[\"abstract\"] are nan\n",
    "    df_no_nan = df_original.dropna(subset=[\"title\", \"abstract\"])\n",
    "    print(f\"Data dimensions after removing nan: {df_no_nan.shape}\")\n",
    "\n",
    "    # preprocess the text\n",
    "    df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
    "    df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n",
    "    corpus = df_no_nan[\"preprocessed_text\"].tolist()\n",
    "\n",
    "    # Create and save index\n",
    "    model = BM11(corpus, tokenizer=nltk.word_tokenize)\n",
    "    pkl_data = {\n",
    "        \"model\": model,\n",
    "        \"data_index\": df_no_nan.index,\n",
    "    }\n",
    "    with open(idxpath, \"wb\") as idx_file:\n",
    "        pickle.dump(pkl_data, idx_file)\n",
    "    return df_original\n",
    "\n",
    "def create_var_15(fpath, idxpath):\n",
    "    \"\"\" Creates index and returns the corpus dataframe\n",
    "    \"\"\"\n",
    "    dataset_file = fpath\n",
    "    col_names = [\"doc_id\", \"category\", \"subcategory\", \"title\",\n",
    "                 \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"]\n",
    "    df_original = pd.read_csv(dataset_file, sep=\"\\t\",\n",
    "                              header=None, names=col_names)\n",
    "    print(f\"Data dimensions: {df_original.shape}\")\n",
    "\n",
    "    # drop when df[\"title\"] & df[\"abstract\"] are nan\n",
    "    df_no_nan = df_original.dropna(subset=[\"title\", \"abstract\"])\n",
    "    print(f\"Data dimensions after removing nan: {df_no_nan.shape}\")\n",
    "\n",
    "    # preprocess the text\n",
    "    df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
    "    df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n",
    "    corpus = df_no_nan[\"preprocessed_text\"].tolist()\n",
    "\n",
    "    # Create and save index\n",
    "    model = BM15(corpus, tokenizer=nltk.word_tokenize)\n",
    "    pkl_data = {\n",
    "        \"model\": model,\n",
    "        \"data_index\": df_no_nan.index,\n",
    "    }\n",
    "    with open(idxpath, \"wb\") as idx_file:\n",
    "        pickle.dump(pkl_data, idx_file)\n",
    "    return df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a936524-ff91-4e2a-88b7-d443fa77b3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/1966928821.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/1966928821.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/1966928821.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/1966928821.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/1966928821.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/1966928821.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/1966928821.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/1966928821.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/1966928821.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/1966928821.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/549525201.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/549525201.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n",
      "/tmp/ipykernel_7197/692976351.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (arr - min_val) / (max_val - min_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25Plus Evaluation against BM25OKapi:  [0, 0, 0, nan]\n",
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/549525201.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/549525201.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25Plus Evaluation against BM25OKapi:  [1.0, 1.0, 1.0, 1.0000000000000018]\n",
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/549525201.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/549525201.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25Plus Evaluation against BM25OKapi:  [1.0, 1.0, 1.0, 0.9999999999999983]\n",
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/549525201.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/549525201.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25Plus Evaluation against BM25OKapi:  [1.0, 1.0, 1.0, 0.9999999999999999]\n",
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/549525201.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/549525201.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25Plus Evaluation against BM25OKapi:  [1.0, 1.0, 1.0, 1.0000000000000027]\n",
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/1966928821.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/1966928821.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n",
      "/tmp/ipykernel_7197/692976351.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (arr - min_val) / (max_val - min_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25L Evaluation against BM25OKapi:  [0, 0, 0, nan]\n",
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/1966928821.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/1966928821.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25L Evaluation against BM25OKapi:  [1.0, 1.0, 1.0, 0.996915548291025]\n",
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/1966928821.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/1966928821.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25L Evaluation against BM25OKapi:  [1.0, 1.0, 1.0, 0.9952283427305206]\n",
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/1966928821.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/1966928821.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25L Evaluation against BM25OKapi:  [1.0, 1.0, 1.0, 0.9776459560262621]\n",
      "Data dimensions: (51282, 8)\n",
      "Data dimensions after removing nan: (48616, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7197/1966928821.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"text\"] = df_no_nan[\"title\"] + \" \" + df_no_nan[\"abstract\"]\n",
      "/tmp/ipykernel_7197/1966928821.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_nan[\"preprocessed_text\"] = df_no_nan[\"text\"].apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25L Evaluation against BM25OKapi:  [1.0, 1.0, 1.0, 0.9396636640484911]\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"data/MINDsmall_train/news.tsv\"\n",
    "INDEX_PATH = \"data/index/news.pickle\"\n",
    "\n",
    "model_variants = ['okapi', 'plus', 'l', '15', '11']\n",
    "\n",
    "sample_queries = ['Gumgal', 'Google', 'It is cold out here in London', 'Ship Wreck', \n",
    "                  'The confluence of technological advancements in artificial intelligence, machine learning, and deep learning has enabled the development of sophisticated neural networks capable of performing complex tasks such as natural language processing, image recognition, and predictive modeling with high accuracy and precision.']\n",
    "bm15_results = []\n",
    "bm11_results = []\n",
    "l_results = []\n",
    "plus_results = []\n",
    "\n",
    "\n",
    "for j in model_variants:\n",
    "    for que in sample_queries:\n",
    "        \n",
    "        if j == 'okapi':\n",
    "            df = create(DATASET_PATH, INDEX_PATH)\n",
    "            model, data_index = load(INDEX_PATH)\n",
    "            query = que\n",
    "            processed_query = preprocess_text(query)\n",
    "            results, scores = model.get_top_var_n(processed_query, data_index, n=10)\n",
    "        \n",
    "            \n",
    "        if j == 'l':\n",
    "            df = create_var_l(DATASET_PATH, INDEX_PATH)\n",
    "            model, data_index = load(INDEX_PATH)\n",
    "            query = que\n",
    "            processed_query = preprocess_text(query)\n",
    "            results, scores = model.get_top_var_n(processed_query, data_index, n=10)\n",
    "            res2, base_scores = model.get_top_n(processed_query, data_index, n=10)\n",
    "            \n",
    "            print('BM25L Evaluation against BM25OKapi: ', model.eval_metr(normalize_array(base_scores), normalize_array(scores)))\n",
    "            l_results.append(model.eval_metr(normalize_array(base_scores), normalize_array(scores)))\n",
    "\n",
    "        if j == 'plus':\n",
    "            df = create_var_plus(DATASET_PATH, INDEX_PATH)\n",
    "            model, data_index = load(INDEX_PATH)\n",
    "            query = que\n",
    "            processed_query = preprocess_text(query)\n",
    "            results, scores = model.get_top_var_n(processed_query, data_index, n=10)\n",
    "            res2, base_scores = model.get_top_n(processed_query, data_index, n=10)\n",
    "            \n",
    "            print('BM25Plus Evaluation against BM25OKapi: ', model.eval_metr(normalize_array(base_scores), normalize_array(scores)))\n",
    "            plus_results.append(model.eval_metr(normalize_array(base_scores), normalize_array(scores)))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd777f37-9f13-4b80-9b57-7881386c4ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "l_st = []\n",
    "plus_st = []\n",
    "overlapping = 0.15\n",
    "for i in range(len(l_results)):\n",
    "        \n",
    "        for j in range(4):\n",
    "            \n",
    "                #ndcg\n",
    "            l_st.append(l_results[i][3])\n",
    "            plus_st.append(plus_results[i][3])\n",
    "            \n",
    "        plt.plot(l_st, label = 'L', color = 'blue',  lw = 2)\n",
    "        plt.plot(plus_st, label = 'Plus', color = 'green', alpha = 0.8, lw = 2)\n",
    "        \n",
    "        plt.title('ndcg')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83ef328f-f739-4240-a588-75f0d40a72c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, nan, 1.0000000000000018, 1.0000000000000018, 1.0000000000000018, 1.0000000000000018, 0.9999999999999983, 0.9999999999999983, 0.9999999999999983, 0.9999999999999983, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 0.9999999999999999, 1.0000000000000027, 1.0000000000000027, 1.0000000000000027, 1.0000000000000027]\n",
      "[nan, nan, nan, nan, 0.996915548291025, 0.996915548291025, 0.996915548291025, 0.996915548291025, 0.9952283427305206, 0.9952283427305206, 0.9952283427305206, 0.9952283427305206, 0.9776459560262621, 0.9776459560262621, 0.9776459560262621, 0.9776459560262621, 0.9396636640484911, 0.9396636640484911, 0.9396636640484911, 0.9396636640484911]\n"
     ]
    }
   ],
   "source": [
    "print(plus_st)\n",
    "print(l_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25b9dc-f404-479d-bcc7-47b3c4a1dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "class BM25Adpt(BM25):\n",
    "    def __init__(self, corpus, tokenizer = None, k1=1.5, b=0.75, delta=1):\n",
    "      # Algorithm specific parameters\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.delta = delta\n",
    "        super().__init__(corpus, tokenizer)\n",
    "#\n",
    "    def _calc_idf(self, nd):\n",
    "        for word, freq in nd.items():\n",
    "            idf = math.log((self.corpus_size + 1) / freq)\n",
    "            self.idf[word] = idf\n",
    "#\n",
    "    def get_scores(self, query):\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (self.delta + (q_freq * (self.k1 + 1)) /\n",
    "                                               (self.k1 * (1 - self.b + self.b * doc_len / self.avgdl) + q_freq))\n",
    "        return score\n",
    "    def get_bm25scores(self, query):\n",
    "        \n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (\n",
    "                q_freq\n",
    "                * (self.k1 + 1)\n",
    "                / (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "            )\n",
    "        return score\n",
    "    \n",
    "class BM25T(BM25):\n",
    "    def __init__(self, corpus, tokenizer = None, k1=1.5, b=0.75, delta=1):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.delta = delta\n",
    "        super().__init__(corpus, tokenizer)\n",
    "#\n",
    "    def _calc_idf(self, nd):\n",
    "        for word, freq in nd.items():\n",
    "            idf = math.log((self.corpus_size + 1) / freq)\n",
    "            self.idf[word] = idf\n",
    "#\n",
    "    def get_scores(self, query):\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (self.delta + (q_freq * (self.k1 + 1)) /\n",
    "                                               (self.k1 * (1 - self.b + self.b * doc_len / self.avgdl) + q_freq))\n",
    "        return score\n",
    "    def get_bm25scores(self, query):\n",
    "        \n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (\n",
    "                q_freq\n",
    "                * (self.k1 + 1)\n",
    "                / (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "            )\n",
    "        return score\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "   \n",
    "class BM11(BM25):\n",
    "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=1, epsilon=0.25):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.epsilon = epsilon\n",
    "        super().__init__(corpus, tokenizer)\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        \n",
    "        # collect idf sum to calculate an average idf for epsilon value\n",
    "        idf_sum = 0\n",
    "        # collect words with negative idf to set them a special epsilon value.\n",
    "        # idf can be negative if word is contained in more than half of documents\n",
    "        negative_idfs = []\n",
    "        for word, freq in nd.items():\n",
    "            idf = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
    "            self.idf[word] = idf\n",
    "            idf_sum += idf\n",
    "            if idf < 0:\n",
    "                negative_idfs.append(word)\n",
    "        self.average_idf = idf_sum / len(self.idf)\n",
    "\n",
    "        eps = self.epsilon * self.average_idf\n",
    "        for word in negative_idfs:\n",
    "            self.idf[word] = eps\n",
    "\n",
    "    def get_bm25scores(self, query):\n",
    "        \n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (\n",
    "                q_freq\n",
    "                * (self.k1 + 1)\n",
    "                / (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "            )\n",
    "        return score\n",
    "    def get_scores(self, query):\n",
    "        \n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (\n",
    "                q_freq\n",
    "                * (self.k1 + 1)\n",
    "                / (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "            )\n",
    "        return score\n",
    "\n",
    "    def get_batch_scores(self, query, doc_ids):\n",
    "        \n",
    "        assert all(di < len(self.doc_freqs) for di in doc_ids)\n",
    "        score = np.zeros(len(doc_ids))\n",
    "        doc_len = np.array(self.doc_len)[doc_ids]\n",
    "        for q in query:\n",
    "            q_freq = np.array([(self.doc_freqs[di].get(q) or 0) for di in doc_ids])\n",
    "            score += (self.idf.get(q) or 0) * (\n",
    "                q_freq\n",
    "                * (self.k1 + 1)\n",
    "                / (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "            )\n",
    "        return score.tolist()\n",
    "    \n",
    "    \n",
    "   \n",
    "class BM15(BM25):\n",
    "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0, epsilon=0.25):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.epsilon = epsilon\n",
    "        super().__init__(corpus, tokenizer)\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        \n",
    "        # collect idf sum to calculate an average idf for epsilon value\n",
    "        idf_sum = 0\n",
    "        # collect words with negative idf to set them a special epsilon value.\n",
    "        # idf can be negative if word is contained in more than half of documents\n",
    "        negative_idfs = []\n",
    "        for word, freq in nd.items():\n",
    "            idf = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
    "            self.idf[word] = idf\n",
    "            idf_sum += idf\n",
    "            if idf < 0:\n",
    "                negative_idfs.append(word)\n",
    "        self.average_idf = idf_sum / len(self.idf)\n",
    "\n",
    "        eps = self.epsilon * self.average_idf\n",
    "        for word in negative_idfs:\n",
    "            self.idf[word] = eps\n",
    "\n",
    "    def get_bm25scores(self, query):\n",
    "        \n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (\n",
    "                q_freq\n",
    "                * (self.k1 + 1)\n",
    "                / (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "            )\n",
    "        return score\n",
    "    def get_scores(self, query):\n",
    "        \n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (\n",
    "                q_freq\n",
    "                * (self.k1 + 1)\n",
    "                / (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "            )\n",
    "        return score\n",
    "\n",
    "    def get_batch_scores(self, query, doc_ids):\n",
    "        \n",
    "        assert all(di < len(self.doc_freqs) for di in doc_ids)\n",
    "        score = np.zeros(len(doc_ids))\n",
    "        doc_len = np.array(self.doc_len)[doc_ids]\n",
    "        for q in query:\n",
    "            q_freq = np.array([(self.doc_freqs[di].get(q) or 0) for di in doc_ids])\n",
    "            score += (self.idf.get(q) or 0) * (\n",
    "                q_freq\n",
    "                * (self.k1 + 1)\n",
    "                / (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "            )\n",
    "        return score.tolist()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
